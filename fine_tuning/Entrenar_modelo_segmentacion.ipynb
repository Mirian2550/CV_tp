{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **DATASET**\n",
        "Url: https://universe.roboflow.com/socrobdatasets/merged-dataset-robocup-2024"
      ],
      "metadata": {
        "id": "n_XvQEG4sAOi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMg4wfGnbiqm",
        "outputId": "b8130b16-49f1-428c-b565-bb709dc9ae63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.9.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-9zosur8l\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-9zosur8l\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit ebe8b45437f86395352ab13402ba45b75b4d1ddb\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (10.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.4.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.17.0)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.1.9)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (1.3.2)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.3.6)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.12.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (71.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install requests pydantic opencv-python gdown\n",
        "!pip install git+https://github.com/facebookresearch/detectron2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbFYPcg8btUI",
        "outputId": "b4a1d25a-27d2-4031-b6fe-2609ea7d3513"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.utils.logger import setup_logger\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "whAEO0bL1zWW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gFZCUR_1dPPC"
      },
      "outputs": [],
      "source": [
        "import torch  # Necesario para detectar la disponibilidad de GPU\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "class FruitSegmentation:\n",
        "    \"\"\"\n",
        "    A class used to download, filter, modify, and train a fruit segmentation model using Detectron2.\n",
        "\n",
        "    Attributes:\n",
        "    -----------\n",
        "    train_dataset_path : str\n",
        "        The path to the training dataset directory.\n",
        "    test_dataset_path : str\n",
        "        The path to the testing dataset directory.\n",
        "    output_dir : str\n",
        "        The directory where the model and results will be saved.\n",
        "    num_classes : int\n",
        "        Number of target classes for segmentation.\n",
        "    base_lr : float\n",
        "        The base learning rate for the model.\n",
        "    max_iter : int\n",
        "        Maximum number of iterations for training.\n",
        "    batch_size : int\n",
        "        The batch size used for training.\n",
        "    num_workers : int\n",
        "        Number of worker threads used for loading data.\n",
        "    device : str\n",
        "        Device used for training and inference (CPU/GPU).\n",
        "    classes_to_keep : list\n",
        "        List of classes to keep from the dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, train_dataset_path, test_dataset_path,\n",
        "                 output_dir=\"segmentacion\", num_classes=4, base_lr=0.0025,\n",
        "                 max_iter=1000, batch_size=2, num_workers=2, device=None):\n",
        "        \"\"\"\n",
        "        Initializes the FruitSegmentation class with dataset paths, training parameters, and filtering setup.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        train_dataset_path : str\n",
        "            The path to the training dataset directory.\n",
        "        test_dataset_path : str\n",
        "            The path to the testing dataset directory.\n",
        "        output_dir : str\n",
        "            The directory where the model and results will be saved.\n",
        "        num_classes : int\n",
        "            Number of target classes for segmentation.\n",
        "        base_lr : float\n",
        "            The base learning rate for the model.\n",
        "        max_iter : int\n",
        "            Maximum number of iterations for training.\n",
        "        batch_size : int\n",
        "            The batch size used for training.\n",
        "        num_workers : int\n",
        "            Number of worker threads used for loading data.\n",
        "        device : str, optional\n",
        "            Device used for training and inference (CPU/GPU). If None, the device will be automatically chosen based on availability.\n",
        "        \"\"\"\n",
        "        self.train_dataset_path = train_dataset_path\n",
        "        self.test_dataset_path = test_dataset_path\n",
        "        self.num_classes = num_classes\n",
        "        self.output_dir = output_dir\n",
        "        self.base_lr = base_lr\n",
        "        self.max_iter = max_iter\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "        # Inicializa la lista de clases a mantener\n",
        "        self.classes_to_keep = ['apple', 'banana', 'orange', 'pear']\n",
        "\n",
        "        # Detectar GPU si está disponible, de lo contrario usar CPU\n",
        "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self._download_dataset()\n",
        "        self._filter_dataset_annotations(self.train_dataset_path)\n",
        "        self._filter_dataset_annotations(self.test_dataset_path)\n",
        "        self._clear_previous_registration()\n",
        "        self._register_datasets()\n",
        "        self.cfg = self._setup_cfg()\n",
        "\n",
        "    def _clear_previous_registration(self):\n",
        "        \"\"\"\n",
        "        Clears any previous dataset registrations to avoid metadata conflicts.\n",
        "        \"\"\"\n",
        "        if \"fruit_dataset_train\" in DatasetCatalog.list():\n",
        "            DatasetCatalog.remove(\"fruit_dataset_train\")\n",
        "            MetadataCatalog.remove(\"fruit_dataset_train\")\n",
        "\n",
        "        if \"fruit_dataset_test\" in DatasetCatalog.list():\n",
        "            DatasetCatalog.remove(\"fruit_dataset_test\")\n",
        "            MetadataCatalog.remove(\"fruit_dataset_test\")\n",
        "\n",
        "    def _download_dataset(self):\n",
        "        \"\"\"\n",
        "        Downloads the dataset from Roboflow if it's not available locally.\n",
        "        \"\"\"\n",
        "        if not os.path.exists(self.train_dataset_path) or not os.path.exists(self.test_dataset_path):\n",
        "            print(\"Descargando el dataset desde Roboflow...\")\n",
        "            subprocess.run(\n",
        "                'curl -L \"https://universe.roboflow.com/ds/L7xp8qMl6k?key=Npf4RqYMud\" > roboflow.zip',\n",
        "                shell=True)\n",
        "            subprocess.run(\"unzip roboflow.zip\", shell=True)\n",
        "            os.remove(\"roboflow.zip\")\n",
        "            print(\"Dataset descargado, extraído y el archivo .zip eliminado.\")\n",
        "        else:\n",
        "            print(\"El dataset ya está disponible.\")\n",
        "\n",
        "    def _filter_dataset_annotations(self, dataset_path):\n",
        "        \"\"\"\n",
        "        Filters out classes and images that do not contain relevant classes.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        dataset_path : str\n",
        "            Path to the dataset directory where the annotations and images are stored.\n",
        "        \"\"\"\n",
        "        json_path = os.path.join(dataset_path, \"_annotations.coco.json\")\n",
        "\n",
        "        with open(json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        filtered_images = []\n",
        "        filtered_annotations = []\n",
        "\n",
        "        class_ids_to_keep = self._get_class_ids_to_keep(data)\n",
        "\n",
        "        for annotation in data['annotations']:\n",
        "            if annotation['category_id'] in class_ids_to_keep:\n",
        "                filtered_annotations.append(annotation)\n",
        "\n",
        "        for image in data['images']:\n",
        "            image_annotations = [a for a in filtered_annotations if a['image_id'] == image['id']]\n",
        "            if image_annotations:\n",
        "                filtered_images.append(image)\n",
        "            else:\n",
        "                image_path = os.path.join(dataset_path, image['file_name'])\n",
        "                if os.path.exists(image_path):\n",
        "                    os.remove(image_path)\n",
        "\n",
        "        data['images'] = filtered_images\n",
        "        data['annotations'] = filtered_annotations\n",
        "        data['categories'] = [c for c in data['categories'] if c['name'] in self.classes_to_keep]\n",
        "\n",
        "        with open(json_path, 'w') as f:\n",
        "            json.dump(data, f)\n",
        "\n",
        "    def _get_class_ids_to_keep(self, data):\n",
        "        \"\"\"\n",
        "        Retrieves the class IDs to keep from the dataset based on the target classes.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        data : dict\n",
        "            The loaded dataset annotation data.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        class_ids_to_keep : list\n",
        "            List of category IDs to keep.\n",
        "        \"\"\"\n",
        "        return [c['id'] for c in data['categories'] if c['name'] in self.classes_to_keep]\n",
        "\n",
        "    def _register_datasets(self):\n",
        "        \"\"\"\n",
        "        Registers the filtered datasets for training and testing in the Detectron2 framework.\n",
        "        \"\"\"\n",
        "        register_coco_instances(\"fruit_dataset_train\", {},\n",
        "                                f\"{self.train_dataset_path}/_annotations.coco.json\", self.train_dataset_path)\n",
        "        register_coco_instances(\"fruit_dataset_test\", {},\n",
        "                                f\"{self.test_dataset_path}/_annotations.coco.json\", self.test_dataset_path)\n",
        "\n",
        "    def _setup_cfg(self):\n",
        "        \"\"\"\n",
        "        Sets up the configuration for the Detectron2 segmentation model and training parameters.\n",
        "        \"\"\"\n",
        "        cfg = get_cfg()\n",
        "        cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "        cfg.DATASETS.TRAIN = (\"fruit_dataset_train\",)\n",
        "        cfg.DATASETS.TEST = (\"fruit_dataset_test\",)\n",
        "        cfg.DATALOADER.NUM_WORKERS = self.num_workers\n",
        "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "        cfg.SOLVER.IMS_PER_BATCH = self.batch_size\n",
        "        cfg.SOLVER.BASE_LR = self.base_lr\n",
        "        cfg.SOLVER.MAX_ITER = self.max_iter\n",
        "        cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "        cfg.MODEL.ROI_HEADS.NUM_CLASSES = self.num_classes\n",
        "        cfg.OUTPUT_DIR = self.output_dir\n",
        "        cfg.MODEL.DEVICE = self.device  # Configura el dispositivo (GPU/CPU)\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "        return cfg\n",
        "\n",
        "    def show_all_classes(self):\n",
        "        \"\"\"\n",
        "        Displays all the available classes in the dataset.\n",
        "        \"\"\"\n",
        "        # Leer las categorías del archivo de anotaciones del conjunto de entrenamiento\n",
        "        with open(f\"{self.train_dataset_path}/_annotations.coco.json\", 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Obtener las clases originales del dataset\n",
        "        original_classes = [category['name'] for category in data['categories']]\n",
        "        print(f\"Original classes in the dataset: {original_classes}\")\n",
        "\n",
        "    def train(self, resume=False):\n",
        "        \"\"\"\n",
        "        Starts the training process for the segmentation model.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        resume : bool\n",
        "            Whether to resume training from the last checkpoint.\n",
        "        \"\"\"\n",
        "        trainer = DefaultTrainer(self.cfg)\n",
        "        trainer.resume_or_load(resume=resume)\n",
        "        trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Entrenamos el Modelo**"
      ],
      "metadata": {
        "id": "B__km_60zX8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_path = \"train\"\n",
        "test_dataset_path = \"valid\"\n",
        "\n",
        "# Inicializar la clase y mostrar las clases\n",
        "fruit_segmentor = FruitSegmentation(train_dataset_path, test_dataset_path)\n",
        "fruit_segmentor.train(resume=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfZ1O3hGjGke",
        "outputId": "f6163ba2-1366-4db4-9901-f6105f092da7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargando el dataset desde Roboflow...\n",
            "Dataset descargado, extraído y el archivo .zip eliminado.\n",
            "[10/03 20:16:54 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [10/03 20:16:54 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[10/03 20:16:54 d2.data.datasets.coco]: Loaded 2384 images in COCO format from train/_annotations.coco.json\n",
            "[10/03 20:16:54 d2.data.build]: Removed 0 images with no usable annotations. 2384 images left.\n",
            "[10/03 20:16:54 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[10/03 20:16:54 d2.data.build]: Using training sampler TrainingSampler\n",
            "[10/03 20:16:54 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[10/03 20:16:54 d2.data.common]: Serializing 2384 elements to byte tensors and concatenating them all ...\n",
            "[10/03 20:16:54 d2.data.common]: Serialized dataset takes 3.18 MiB\n",
            "[10/03 20:16:54 d2.data.build]: Making batched data loader with batch_size=2\n",
            "WARNING [10/03 20:16:54 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[10/03 20:16:54 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n",
            "roi_heads.mask_head.predictor.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10/03 20:16:55 d2.engine.train_loop]: Starting training from iteration 0\n",
            "[10/03 20:17:06 d2.utils.events]:  eta: 0:08:54  iter: 19  total_loss: 2.768  loss_cls: 1.565  loss_box_reg: 0.4752  loss_mask: 0.6887  loss_rpn_cls: 0.02185  loss_rpn_loc: 0.005474    time: 0.5389  last_time: 0.5109  data_time: 0.0342  last_data_time: 0.0276   lr: 4.9952e-05  max_mem: 3258M\n",
            "[10/03 20:17:16 d2.utils.events]:  eta: 0:08:39  iter: 39  total_loss: 2.134  loss_cls: 0.9237  loss_box_reg: 0.4967  loss_mask: 0.6308  loss_rpn_cls: 0.0238  loss_rpn_loc: 0.006627    time: 0.5371  last_time: 0.5710  data_time: 0.0151  last_data_time: 0.0296   lr: 9.9902e-05  max_mem: 3258M\n",
            "[10/03 20:17:27 d2.utils.events]:  eta: 0:08:32  iter: 59  total_loss: 1.663  loss_cls: 0.5627  loss_box_reg: 0.5425  loss_mask: 0.5304  loss_rpn_cls: 0.0193  loss_rpn_loc: 0.006095    time: 0.5396  last_time: 0.5606  data_time: 0.0171  last_data_time: 0.0156   lr: 0.00014985  max_mem: 3258M\n",
            "[10/03 20:17:38 d2.utils.events]:  eta: 0:08:23  iter: 79  total_loss: 1.449  loss_cls: 0.4706  loss_box_reg: 0.543  loss_mask: 0.3953  loss_rpn_cls: 0.0176  loss_rpn_loc: 0.006827    time: 0.5425  last_time: 0.5514  data_time: 0.0184  last_data_time: 0.0135   lr: 0.0001998  max_mem: 3258M\n",
            "[10/03 20:17:49 d2.utils.events]:  eta: 0:08:10  iter: 99  total_loss: 1.389  loss_cls: 0.4134  loss_box_reg: 0.6282  loss_mask: 0.293  loss_rpn_cls: 0.01444  loss_rpn_loc: 0.005771    time: 0.5397  last_time: 0.5648  data_time: 0.0096  last_data_time: 0.0067   lr: 0.00024975  max_mem: 3258M\n",
            "[10/03 20:18:00 d2.utils.events]:  eta: 0:07:56  iter: 119  total_loss: 1.21  loss_cls: 0.3523  loss_box_reg: 0.6148  loss_mask: 0.2526  loss_rpn_cls: 0.02076  loss_rpn_loc: 0.007241    time: 0.5378  last_time: 0.4629  data_time: 0.0110  last_data_time: 0.0070   lr: 0.0002997  max_mem: 3258M\n",
            "[10/03 20:18:10 d2.utils.events]:  eta: 0:07:46  iter: 139  total_loss: 1.108  loss_cls: 0.3157  loss_box_reg: 0.5521  loss_mask: 0.1519  loss_rpn_cls: 0.01291  loss_rpn_loc: 0.004607    time: 0.5376  last_time: 0.5056  data_time: 0.0160  last_data_time: 0.0175   lr: 0.00034965  max_mem: 3258M\n",
            "[10/03 20:18:21 d2.utils.events]:  eta: 0:07:34  iter: 159  total_loss: 0.9115  loss_cls: 0.261  loss_box_reg: 0.3762  loss_mask: 0.1213  loss_rpn_cls: 0.006179  loss_rpn_loc: 0.004855    time: 0.5359  last_time: 0.5472  data_time: 0.0149  last_data_time: 0.0184   lr: 0.0003996  max_mem: 3258M\n",
            "[10/03 20:18:31 d2.utils.events]:  eta: 0:07:23  iter: 179  total_loss: 0.6956  loss_cls: 0.18  loss_box_reg: 0.3498  loss_mask: 0.1099  loss_rpn_cls: 0.01023  loss_rpn_loc: 0.006304    time: 0.5356  last_time: 0.4901  data_time: 0.0153  last_data_time: 0.0155   lr: 0.00044955  max_mem: 3258M\n",
            "[10/03 20:18:42 d2.utils.events]:  eta: 0:07:13  iter: 199  total_loss: 0.5682  loss_cls: 0.2018  loss_box_reg: 0.2703  loss_mask: 0.1033  loss_rpn_cls: 0.004083  loss_rpn_loc: 0.005521    time: 0.5365  last_time: 0.5885  data_time: 0.0135  last_data_time: 0.0241   lr: 0.0004995  max_mem: 3258M\n",
            "[10/03 20:18:53 d2.utils.events]:  eta: 0:07:02  iter: 219  total_loss: 0.4624  loss_cls: 0.1498  loss_box_reg: 0.2105  loss_mask: 0.09877  loss_rpn_cls: 0.008056  loss_rpn_loc: 0.007106    time: 0.5364  last_time: 0.4575  data_time: 0.0127  last_data_time: 0.0190   lr: 0.00054945  max_mem: 3258M\n",
            "[10/03 20:19:04 d2.utils.events]:  eta: 0:06:52  iter: 239  total_loss: 0.4984  loss_cls: 0.147  loss_box_reg: 0.1898  loss_mask: 0.09266  loss_rpn_cls: 0.01135  loss_rpn_loc: 0.006539    time: 0.5374  last_time: 0.5459  data_time: 0.0106  last_data_time: 0.0062   lr: 0.0005994  max_mem: 3258M\n",
            "[10/03 20:19:14 d2.utils.events]:  eta: 0:06:41  iter: 259  total_loss: 0.4574  loss_cls: 0.1162  loss_box_reg: 0.1954  loss_mask: 0.08339  loss_rpn_cls: 0.007307  loss_rpn_loc: 0.005999    time: 0.5357  last_time: 0.5602  data_time: 0.0108  last_data_time: 0.0108   lr: 0.00064935  max_mem: 3258M\n",
            "[10/03 20:19:25 d2.utils.events]:  eta: 0:06:29  iter: 279  total_loss: 0.4599  loss_cls: 0.1093  loss_box_reg: 0.1957  loss_mask: 0.0835  loss_rpn_cls: 0.005186  loss_rpn_loc: 0.005352    time: 0.5354  last_time: 0.5023  data_time: 0.0141  last_data_time: 0.0077   lr: 0.0006993  max_mem: 3258M\n",
            "[10/03 20:19:36 d2.utils.events]:  eta: 0:06:19  iter: 299  total_loss: 0.4021  loss_cls: 0.1131  loss_box_reg: 0.2041  loss_mask: 0.09796  loss_rpn_cls: 0.003423  loss_rpn_loc: 0.005609    time: 0.5352  last_time: 0.5103  data_time: 0.0153  last_data_time: 0.0206   lr: 0.00074925  max_mem: 3258M\n",
            "[10/03 20:19:47 d2.utils.events]:  eta: 0:06:08  iter: 319  total_loss: 0.4144  loss_cls: 0.1324  loss_box_reg: 0.1839  loss_mask: 0.08502  loss_rpn_cls: 0.004105  loss_rpn_loc: 0.004293    time: 0.5355  last_time: 0.5586  data_time: 0.0138  last_data_time: 0.0129   lr: 0.0007992  max_mem: 3258M\n",
            "[10/03 20:19:57 d2.utils.events]:  eta: 0:05:58  iter: 339  total_loss: 0.384  loss_cls: 0.1241  loss_box_reg: 0.1548  loss_mask: 0.09572  loss_rpn_cls: 0.008033  loss_rpn_loc: 0.006575    time: 0.5362  last_time: 0.5630  data_time: 0.0166  last_data_time: 0.0128   lr: 0.00084915  max_mem: 3258M\n",
            "[10/03 20:20:08 d2.utils.events]:  eta: 0:05:47  iter: 359  total_loss: 0.4456  loss_cls: 0.1083  loss_box_reg: 0.2181  loss_mask: 0.1113  loss_rpn_cls: 0.006689  loss_rpn_loc: 0.007441    time: 0.5355  last_time: 0.5697  data_time: 0.0107  last_data_time: 0.0198   lr: 0.0008991  max_mem: 3258M\n",
            "[10/03 20:20:19 d2.utils.events]:  eta: 0:05:36  iter: 379  total_loss: 0.372  loss_cls: 0.09285  loss_box_reg: 0.1544  loss_mask: 0.08035  loss_rpn_cls: 0.006227  loss_rpn_loc: 0.005327    time: 0.5357  last_time: 0.5600  data_time: 0.0150  last_data_time: 0.0109   lr: 0.00094905  max_mem: 3258M\n",
            "[10/03 20:20:30 d2.utils.events]:  eta: 0:05:25  iter: 399  total_loss: 0.3659  loss_cls: 0.09622  loss_box_reg: 0.1514  loss_mask: 0.09645  loss_rpn_cls: 0.02106  loss_rpn_loc: 0.006951    time: 0.5359  last_time: 0.5839  data_time: 0.0180  last_data_time: 0.0234   lr: 0.000999  max_mem: 3258M\n",
            "[10/03 20:20:40 d2.utils.events]:  eta: 0:05:14  iter: 419  total_loss: 0.3344  loss_cls: 0.07921  loss_box_reg: 0.1325  loss_mask: 0.08088  loss_rpn_cls: 0.009688  loss_rpn_loc: 0.005572    time: 0.5353  last_time: 0.5198  data_time: 0.0111  last_data_time: 0.0062   lr: 0.001049  max_mem: 3258M\n",
            "[10/03 20:20:51 d2.utils.events]:  eta: 0:05:03  iter: 439  total_loss: 0.3348  loss_cls: 0.07358  loss_box_reg: 0.1552  loss_mask: 0.07621  loss_rpn_cls: 0.005536  loss_rpn_loc: 0.006038    time: 0.5355  last_time: 0.4527  data_time: 0.0165  last_data_time: 0.0073   lr: 0.0010989  max_mem: 3258M\n",
            "[10/03 20:21:02 d2.utils.events]:  eta: 0:04:52  iter: 459  total_loss: 0.3421  loss_cls: 0.08653  loss_box_reg: 0.1903  loss_mask: 0.08178  loss_rpn_cls: 0.004026  loss_rpn_loc: 0.005562    time: 0.5354  last_time: 0.5729  data_time: 0.0112  last_data_time: 0.0061   lr: 0.0011489  max_mem: 3258M\n",
            "[10/03 20:21:12 d2.utils.events]:  eta: 0:04:41  iter: 479  total_loss: 0.4165  loss_cls: 0.1098  loss_box_reg: 0.1865  loss_mask: 0.07729  loss_rpn_cls: 0.003371  loss_rpn_loc: 0.006021    time: 0.5351  last_time: 0.4807  data_time: 0.0125  last_data_time: 0.0074   lr: 0.0011988  max_mem: 3258M\n",
            "[10/03 20:21:23 d2.utils.events]:  eta: 0:04:31  iter: 499  total_loss: 0.2915  loss_cls: 0.08907  loss_box_reg: 0.1239  loss_mask: 0.06794  loss_rpn_cls: 0.003371  loss_rpn_loc: 0.005267    time: 0.5355  last_time: 0.5669  data_time: 0.0169  last_data_time: 0.0302   lr: 0.0012488  max_mem: 3258M\n",
            "[10/03 20:21:34 d2.utils.events]:  eta: 0:04:20  iter: 519  total_loss: 0.3469  loss_cls: 0.08531  loss_box_reg: 0.1402  loss_mask: 0.08164  loss_rpn_cls: 0.004987  loss_rpn_loc: 0.004588    time: 0.5352  last_time: 0.4733  data_time: 0.0093  last_data_time: 0.0154   lr: 0.0012987  max_mem: 3258M\n",
            "[10/03 20:21:44 d2.utils.events]:  eta: 0:04:09  iter: 539  total_loss: 0.3652  loss_cls: 0.0995  loss_box_reg: 0.1488  loss_mask: 0.07329  loss_rpn_cls: 0.003194  loss_rpn_loc: 0.006594    time: 0.5351  last_time: 0.5367  data_time: 0.0139  last_data_time: 0.0065   lr: 0.0013487  max_mem: 3258M\n",
            "[10/03 20:21:55 d2.utils.events]:  eta: 0:03:58  iter: 559  total_loss: 0.3278  loss_cls: 0.08757  loss_box_reg: 0.15  loss_mask: 0.07224  loss_rpn_cls: 0.01083  loss_rpn_loc: 0.008421    time: 0.5349  last_time: 0.5800  data_time: 0.0132  last_data_time: 0.0277   lr: 0.0013986  max_mem: 3258M\n",
            "[10/03 20:22:05 d2.utils.events]:  eta: 0:03:47  iter: 579  total_loss: 0.317  loss_cls: 0.06534  loss_box_reg: 0.1381  loss_mask: 0.06991  loss_rpn_cls: 0.01009  loss_rpn_loc: 0.006563    time: 0.5343  last_time: 0.4237  data_time: 0.0137  last_data_time: 0.0095   lr: 0.0014486  max_mem: 3258M\n",
            "[10/03 20:22:16 d2.utils.events]:  eta: 0:03:36  iter: 599  total_loss: 0.3612  loss_cls: 0.1118  loss_box_reg: 0.1533  loss_mask: 0.08769  loss_rpn_cls: 0.004166  loss_rpn_loc: 0.006532    time: 0.5346  last_time: 0.5352  data_time: 0.0172  last_data_time: 0.0057   lr: 0.0014985  max_mem: 3258M\n",
            "[10/03 20:22:27 d2.utils.events]:  eta: 0:03:25  iter: 619  total_loss: 0.395  loss_cls: 0.09281  loss_box_reg: 0.2022  loss_mask: 0.0819  loss_rpn_cls: 0.001658  loss_rpn_loc: 0.007261    time: 0.5343  last_time: 0.5644  data_time: 0.0119  last_data_time: 0.0062   lr: 0.0015485  max_mem: 3258M\n",
            "[10/03 20:22:38 d2.utils.events]:  eta: 0:03:15  iter: 639  total_loss: 0.3776  loss_cls: 0.1098  loss_box_reg: 0.1833  loss_mask: 0.07295  loss_rpn_cls: 0.002912  loss_rpn_loc: 0.005969    time: 0.5347  last_time: 0.4686  data_time: 0.0147  last_data_time: 0.0160   lr: 0.0015984  max_mem: 3258M\n",
            "[10/03 20:22:49 d2.utils.events]:  eta: 0:03:04  iter: 659  total_loss: 0.3596  loss_cls: 0.09746  loss_box_reg: 0.1776  loss_mask: 0.06698  loss_rpn_cls: 0.002023  loss_rpn_loc: 0.005215    time: 0.5351  last_time: 0.5901  data_time: 0.0180  last_data_time: 0.0254   lr: 0.0016484  max_mem: 3258M\n",
            "[10/03 20:22:59 d2.utils.events]:  eta: 0:02:53  iter: 679  total_loss: 0.3837  loss_cls: 0.1007  loss_box_reg: 0.1969  loss_mask: 0.07249  loss_rpn_cls: 0.002033  loss_rpn_loc: 0.006449    time: 0.5351  last_time: 0.4776  data_time: 0.0095  last_data_time: 0.0069   lr: 0.0016983  max_mem: 3258M\n",
            "[10/03 20:23:10 d2.utils.events]:  eta: 0:02:43  iter: 699  total_loss: 0.4334  loss_cls: 0.1086  loss_box_reg: 0.1843  loss_mask: 0.08692  loss_rpn_cls: 0.003952  loss_rpn_loc: 0.005321    time: 0.5355  last_time: 0.5411  data_time: 0.0175  last_data_time: 0.0064   lr: 0.0017483  max_mem: 3258M\n",
            "[10/03 20:23:21 d2.utils.events]:  eta: 0:02:32  iter: 719  total_loss: 0.3406  loss_cls: 0.08258  loss_box_reg: 0.1687  loss_mask: 0.08882  loss_rpn_cls: 0.001619  loss_rpn_loc: 0.005192    time: 0.5350  last_time: 0.5858  data_time: 0.0092  last_data_time: 0.0335   lr: 0.0017982  max_mem: 3258M\n",
            "[10/03 20:23:31 d2.utils.events]:  eta: 0:02:21  iter: 739  total_loss: 0.2974  loss_cls: 0.07928  loss_box_reg: 0.1429  loss_mask: 0.06555  loss_rpn_cls: 0.00303  loss_rpn_loc: 0.0036    time: 0.5349  last_time: 0.4817  data_time: 0.0149  last_data_time: 0.0068   lr: 0.0018482  max_mem: 3258M\n",
            "[10/03 20:23:42 d2.utils.events]:  eta: 0:02:10  iter: 759  total_loss: 0.3934  loss_cls: 0.1215  loss_box_reg: 0.1891  loss_mask: 0.07744  loss_rpn_cls: 0.003279  loss_rpn_loc: 0.006327    time: 0.5355  last_time: 0.5427  data_time: 0.0190  last_data_time: 0.0131   lr: 0.0018981  max_mem: 3258M\n",
            "[10/03 20:23:53 d2.utils.events]:  eta: 0:01:59  iter: 779  total_loss: 0.3808  loss_cls: 0.1243  loss_box_reg: 0.1674  loss_mask: 0.0684  loss_rpn_cls: 0.004464  loss_rpn_loc: 0.004809    time: 0.5351  last_time: 0.5249  data_time: 0.0114  last_data_time: 0.0253   lr: 0.0019481  max_mem: 3258M\n",
            "[10/03 20:24:04 d2.utils.events]:  eta: 0:01:48  iter: 799  total_loss: 0.4013  loss_cls: 0.09206  loss_box_reg: 0.2051  loss_mask: 0.08216  loss_rpn_cls: 0.00381  loss_rpn_loc: 0.007191    time: 0.5362  last_time: 0.5317  data_time: 0.0183  last_data_time: 0.0136   lr: 0.001998  max_mem: 3258M\n",
            "[10/03 20:24:15 d2.utils.events]:  eta: 0:01:37  iter: 819  total_loss: 0.3377  loss_cls: 0.0589  loss_box_reg: 0.1742  loss_mask: 0.06958  loss_rpn_cls: 0.00124  loss_rpn_loc: 0.0063    time: 0.5364  last_time: 0.5434  data_time: 0.0171  last_data_time: 0.0066   lr: 0.002048  max_mem: 3258M\n",
            "[10/03 20:24:26 d2.utils.events]:  eta: 0:01:27  iter: 839  total_loss: 0.3543  loss_cls: 0.08429  loss_box_reg: 0.1642  loss_mask: 0.06333  loss_rpn_cls: 0.001378  loss_rpn_loc: 0.004357    time: 0.5364  last_time: 0.5494  data_time: 0.0103  last_data_time: 0.0158   lr: 0.0020979  max_mem: 3258M\n",
            "[10/03 20:24:37 d2.utils.events]:  eta: 0:01:16  iter: 859  total_loss: 0.421  loss_cls: 0.1308  loss_box_reg: 0.167  loss_mask: 0.07681  loss_rpn_cls: 0.002094  loss_rpn_loc: 0.004928    time: 0.5363  last_time: 0.5483  data_time: 0.0199  last_data_time: 0.0077   lr: 0.0021479  max_mem: 3258M\n",
            "[10/03 20:24:47 d2.utils.events]:  eta: 0:01:05  iter: 879  total_loss: 0.3837  loss_cls: 0.1227  loss_box_reg: 0.1716  loss_mask: 0.08415  loss_rpn_cls: 0.003341  loss_rpn_loc: 0.007361    time: 0.5362  last_time: 0.5753  data_time: 0.0138  last_data_time: 0.0415   lr: 0.0021978  max_mem: 3258M\n",
            "[10/03 20:24:58 d2.utils.events]:  eta: 0:00:54  iter: 899  total_loss: 0.3056  loss_cls: 0.06144  loss_box_reg: 0.1557  loss_mask: 0.06901  loss_rpn_cls: 0.004756  loss_rpn_loc: 0.004018    time: 0.5360  last_time: 0.5344  data_time: 0.0159  last_data_time: 0.0140   lr: 0.0022478  max_mem: 3258M\n",
            "[10/03 20:25:09 d2.utils.events]:  eta: 0:00:43  iter: 919  total_loss: 0.3604  loss_cls: 0.0887  loss_box_reg: 0.1882  loss_mask: 0.07155  loss_rpn_cls: 0.005669  loss_rpn_loc: 0.006279    time: 0.5361  last_time: 0.5777  data_time: 0.0150  last_data_time: 0.0235   lr: 0.0022977  max_mem: 3258M\n",
            "[10/03 20:25:19 d2.utils.events]:  eta: 0:00:32  iter: 939  total_loss: 0.2919  loss_cls: 0.07659  loss_box_reg: 0.143  loss_mask: 0.07445  loss_rpn_cls: 0.005578  loss_rpn_loc: 0.00435    time: 0.5359  last_time: 0.5469  data_time: 0.0113  last_data_time: 0.0067   lr: 0.0023477  max_mem: 3258M\n",
            "[10/03 20:25:30 d2.utils.events]:  eta: 0:00:21  iter: 959  total_loss: 0.3048  loss_cls: 0.07519  loss_box_reg: 0.1647  loss_mask: 0.06653  loss_rpn_cls: 0.001346  loss_rpn_loc: 0.005104    time: 0.5360  last_time: 0.5312  data_time: 0.0169  last_data_time: 0.0142   lr: 0.0023976  max_mem: 3258M\n",
            "[10/03 20:25:41 d2.utils.events]:  eta: 0:00:10  iter: 979  total_loss: 0.3535  loss_cls: 0.06499  loss_box_reg: 0.1971  loss_mask: 0.0856  loss_rpn_cls: 0.00131  loss_rpn_loc: 0.004873    time: 0.5358  last_time: 0.5674  data_time: 0.0115  last_data_time: 0.0079   lr: 0.0024476  max_mem: 3258M\n",
            "[10/03 20:25:56 d2.utils.events]:  eta: 0:00:00  iter: 999  total_loss: 0.412  loss_cls: 0.1118  loss_box_reg: 0.1922  loss_mask: 0.07607  loss_rpn_cls: 0.002928  loss_rpn_loc: 0.006787    time: 0.5355  last_time: 0.5529  data_time: 0.0140  last_data_time: 0.0134   lr: 0.0024975  max_mem: 3258M\n",
            "[10/03 20:25:57 d2.engine.hooks]: Overall training speed: 998 iterations in 0:08:54 (0.5355 s / it)\n",
            "[10/03 20:25:57 d2.engine.hooks]: Total training time: 0:09:00 (0:00:06 on hooks)\n",
            "WARNING [10/03 20:25:57 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[10/03 20:25:57 d2.data.datasets.coco]: Loaded 98 images in COCO format from valid/_annotations.coco.json\n",
            "[10/03 20:25:57 d2.data.build]: Distribution of instances among all 4 categories:\n",
            "|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
            "|   apple    | 48           |   banana   | 56           |   orange   | 55           |\n",
            "|    pear    | 45           |            |              |            |              |\n",
            "|   total    | 204          |            |              |            |              |\n",
            "[10/03 20:25:57 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[10/03 20:25:57 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[10/03 20:25:57 d2.data.common]: Serializing 98 elements to byte tensors and concatenating them all ...\n",
            "[10/03 20:25:57 d2.data.common]: Serialized dataset takes 0.10 MiB\n",
            "WARNING [10/03 20:25:57 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.checkpoint import DetectionCheckpointer\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "# Configurar la configuración de Detectron2 para evaluación\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TEST = (\"fruit_dataset_test\",)  # Dataset de prueba\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = \"segmentacion/model_final.pth\"  # Ruta de tu modelo guardado\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4  # Número de clases\n",
        "cfg.MODEL.DEVICE = \"cuda\"  # O \"cpu\" si no tienes GPU\n",
        "\n",
        "# Cargar el modelo entrenado sin iniciar de nuevo el entrenamiento\n",
        "model = DefaultTrainer.build_model(cfg)\n",
        "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
        "\n",
        "# Crear el evaluador y el dataloader de prueba\n",
        "evaluator = COCOEvaluator(\"fruit_dataset_test\", cfg, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"fruit_dataset_test\")\n",
        "\n",
        "# Ejecutar la evaluación y obtener las métricas\n",
        "metrics = inference_on_dataset(model, val_loader, evaluator)\n",
        "print(metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIjn-XH7AiTS",
        "outputId": "9dffdad4-b9e4-4330-cc40-1a4c46f25d86"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10/03 20:27:33 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[10/03 20:27:33 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from segmentacion/model_final.pth ...\n",
            "WARNING [10/03 20:27:33 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "WARNING [10/03 20:27:33 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[10/03 20:27:33 d2.data.datasets.coco]: Loaded 98 images in COCO format from valid/_annotations.coco.json\n",
            "[10/03 20:27:33 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[10/03 20:27:33 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[10/03 20:27:33 d2.data.common]: Serializing 98 elements to byte tensors and concatenating them all ...\n",
            "[10/03 20:27:33 d2.data.common]: Serialized dataset takes 0.10 MiB\n",
            "[10/03 20:27:33 d2.evaluation.evaluator]: Start inference on 98 batches\n",
            "[10/03 20:27:35 d2.evaluation.evaluator]: Inference done 11/98. Dataloading: 0.0018 s/iter. Inference: 0.1171 s/iter. Eval: 0.0261 s/iter. Total: 0.1449 s/iter. ETA=0:00:12\n",
            "[10/03 20:27:40 d2.evaluation.evaluator]: Inference done 46/98. Dataloading: 0.0023 s/iter. Inference: 0.1186 s/iter. Eval: 0.0257 s/iter. Total: 0.1467 s/iter. ETA=0:00:07\n",
            "[10/03 20:27:45 d2.evaluation.evaluator]: Inference done 79/98. Dataloading: 0.0028 s/iter. Inference: 0.1205 s/iter. Eval: 0.0259 s/iter. Total: 0.1493 s/iter. ETA=0:00:02\n",
            "[10/03 20:27:49 d2.evaluation.evaluator]: Total inference time: 0:00:14.414899 (0.154999 s / iter per device, on 1 devices)\n",
            "[10/03 20:27:49 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.122413 s / iter per device, on 1 devices)\n",
            "[10/03 20:27:49 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[10/03 20:27:49 d2.evaluation.coco_evaluation]: Saving results to ./output/coco_instances_results.json\n",
            "[10/03 20:27:49 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[10/03 20:27:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[10/03 20:27:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.\n",
            "[10/03 20:27:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[10/03 20:27:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.688\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.884\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.849\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.649\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.659\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.737\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.724\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.788\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.788\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.708\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.769\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.812\n",
            "[10/03 20:27:49 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 68.761 | 88.443 | 84.858 | 64.942 | 65.908 | 73.726 |\n",
            "[10/03 20:27:49 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| apple      | 72.531 | banana     | 72.163 | orange     | 55.577 |\n",
            "| pear       | 74.774 |            |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[10/03 20:27:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[10/03 20:27:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.\n",
            "[10/03 20:27:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[10/03 20:27:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.765\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.884\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.858\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.691\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.731\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.849\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.788\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.856\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.856\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.775\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.825\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.910\n",
            "[10/03 20:27:49 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 76.547 | 88.443 | 85.806 | 69.134 | 73.062 | 84.935 |\n",
            "[10/03 20:27:49 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| apple      | 80.504 | banana     | 78.450 | orange     | 65.974 |\n",
            "| pear       | 81.261 |            |        |            |        |\n",
            "OrderedDict([('bbox', {'AP': 68.76144869133681, 'AP50': 88.44302893145688, 'AP75': 84.85836916077523, 'APs': 64.94224422442244, 'APm': 65.90821782222635, 'APl': 73.72607703764884, 'AP-apple': 72.53119422664197, 'AP-banana': 72.16330605903347, 'AP-orange': 55.57715619983847, 'AP-pear': 74.77413827983335}), ('segm', {'AP': 76.54715141384138, 'AP50': 88.44302893145688, 'AP75': 85.80649708150261, 'APs': 69.13366336633663, 'APm': 73.06246084597106, 'APl': 84.935269997588, 'AP-apple': 80.50404144750998, 'AP-banana': 78.44951235034101, 'AP-orange': 65.9735863432597, 'AP-pear': 81.26146551425481})])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GUARDAMOS MODELO EN DRIVE**"
      ],
      "metadata": {
        "id": "V6ydalaFy7zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "src = '/content/segmentacion'\n",
        "dst = '/content/drive/MyDrive/modelos_entrenados/segmentacion'\n",
        "shutil.copytree(src, dst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OrmV8M3JzGFY",
        "outputId": "8406f400-bafa-45e0-a2a7-dfb4f53852f1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/modelos_entrenados/segmentacion'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.rmtree('train')\n",
        "shutil.rmtree('test')\n",
        "shutil.rmtree('valid')\n",
        "shutil.rmtree('segmentacion')"
      ],
      "metadata": {
        "id": "Ck-g50r_lbP1"
      },
      "execution_count": 20,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}